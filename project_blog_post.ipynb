{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "bibliography: refs.bib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Blog Post\n",
    "2024-05-17\n",
    "Wow! You completed an awesome project with your group. It’s time for you to tell the world (and especially me) about it on your blog.\n",
    "\n",
    "Your project blog post is the authoritative description of what you achieved and what you learned. It should describe all the achievement, effort, and learning that you want us to factor in to your final grade in the course. Your blog post should have eight sections, which are described below.\n",
    "\n",
    "You can write the first seven sections of your blog post as a group and all post them on your separate blogs. If you take this path, you should just make sure to note it. The final section should be completed individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Abstract\n",
    "\n",
    "For this project, we addressed the problem of audio files containing background noise. We worked with data containing clean speech files and also those same speech files with added background noise, and we created a neural network model to classify a wav file as noisy or not.\n",
    "Overall, our model was very successful, obtaining an evaluation rate on test data of 98.9%. \n",
    "\n",
    "Github repository: [denoising](https://github.com/jblake05/CS0451_Denoising)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Introduction\n",
    "<!-- \n",
    "Your introduction should describe the big-picture problem that you aimed to address in your project. What’s the problem to be solved, and why is it important? Who has tried solving this problem already, and what did they do? I would expect most introductions to reference no fewer than 2 scholarly studies that attempted similar tasks, although 5 is probably a better target.\n",
    "\n",
    "You may be able to recycle some content from your project proposal for your introduction.\n",
    "\n",
    "When citing scholarly studies in a blog post, please use Quarto citations. For a quick overview, see the appendix on references in Quarto. -->\n",
    "\n",
    "This project aims to address the first step in denoising audio signals: classifying the presence of noise. In particular, we aimed to classify added noise in speech signals. Denoising can be used in various ways, essential in providing cleaner signals in music production, restoring historical recordings @moliner_two-stage_2022, or even studying our environment (as in the research on noise filtering for beehives from @varkonyi_dynamic_2023). Previous attempts at audio classification and denoising use various methods of processing signals. A study by @mcloughlin_timefrequency_2020 used a combination of a spectrogram and a cochleogram (both 2D representations of an audio signal) alongside convolutional and fully connected layers for their model. Similarly, @verhaegh_algorithms_2004 tests the efficacy of different processing techniques, finding that running a signal through a sequence of filterbanks achieves the highest accuracy overall (90% across different classification tasks including noise). They also found the use of a mel-frequency cepstrum (MFCC) to be highly effective at 85% average accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Values Statement\n",
    "\n",
    "We expect the users of our project to be engineers and/or musicians. This project is the groundwork for Denoising - removing the background noise from speech audio, resulting in clean, understandable audio. This is incredibly helpful not only for music, but any applications that convert speech to digital audio - for example: enhancing phone call quality, and speech-to-text accuracy, which many people will benefit from.\n",
    "\n",
    "While we hope these applications will only improve the quality of life for people using these tools, we must understand a potential source of bias in the data: all the audio clips are spoken in English. If this is the only project/data used in denoising applications and is applied to technology used by those who speak other languages, it could potentially diminish the quality of their audio.\n",
    "\n",
    "Our motivation for this project stems from our interest in electronic music. Vocals are particularly tricky to mix well (sound good within a track), and it makes a world of difference when the incoming audio file has been recorded at a high quality. Historically the way to accomplish this is with high-grade equipment, which can be very expensive. Using denoising software is a cost-effective alternative for clean vocal files for producing music.\n",
    "\n",
    "The core question of this project is: would the world be a more equitable, just, joyful, peaceful, or sustainable place based on this technology? We believe that as long as more audio of all languages is incorporated, the answer is **yes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Materials and Methods\n",
    "\n",
    "## Your Data\n",
    "\n",
    "<!-- Include some discussion of where it came from, who collected it (include a citation), how it was collected, and what each row represents (a person, an environmental event, a body of text, etc) Please also include a discussion of potential limitations in the data: who or what is represented, and who or what isn’t?\n",
    "\n",
    "In structuring your description of the data, I encourage you to address many of the questions outlined in Gebru et al. (2021), although it is not necessary for you to write a complete data sheet for your data set. -->\n",
    "\n",
    "Our project is based on the data from the Microsoft Scalable Noisy Speech Dataset @reddy2019scalable. This dataset obtained access to two speech datasets by license, one from the University of Edinburgh @inproceedings (where speakers across Great Britain were recruited by advertisement) and one from Graz University @Pirker2011APT (recruiting native English speakers through advertisements at various institutions). Similarly, MS-SNSD obtained noise samples by license from freesound.org (a website which allows for user submitted sound samples) and from the DEMAND dataset by @thiemann_demand_2013. As such, these samples were created by researchers or freesound.org users recording their environments (traffic, public noising, appliances humming, etc.). The MS-SNSD provides a Python program to automatically combine the speech and noise data.\n",
    "\n",
    "After reading in the data from a wav file, we converted it to a mels-spectrogram. Each row (or 2D array before flattening) of the data represents one audio file as a mels-spectrogram. These audio signals are 10 seconds of speech, either clean (no noise) or accompanied with added background noise. One limitation that exists with this dataset is that it does not contain  recordings of languages other than English. As such, training a model on it does not guarantee its usefulness across languages.\n",
    "\n",
    "## Your Approach\n",
    "<!-- This is the primary section where you should describe what you did. Carefully describe:\n",
    "\n",
    "- What features of your data you used as predictors for your models, and what features (if any) you used as targets.\n",
    "- Whether you subset your data in any way, and for what reasons.\n",
    "- What model(s) you used trained on your data, and how you chose them.\n",
    "- How you trained your models, and on what hardware.\n",
    "- How you evaluated your models (loss, accuracy, etc), and the size of your test set.\n",
    "- If you performed an audit for bias, how you approached this and what metrics you used. -->\n",
    "\n",
    "In the processing of our data, we used the mels-spectrogram representation of 160000 sample audio files (cut off at exactly 10 seconds for consistent sizing). In converting these audio files to spectrograms, we had data instances of size 128 x 313 pixels, or 40064 features per instance of data. For our targets, we just created a vector that represented whether or not an audio sample had noise added (1 if noise is present, 0 if the signal is clean). We used a subset of our data (around ~3200 audio files) in order to limit training time. Our model was trained on Google Colab using the T4 GPU when available (and its default CPU when not); our model consisted of a convolutional layer, and linear layer. While we tried to add more complexity to our model, we immediately saw a dip in accuracy (and our accuracy results with the current model were already promising). We evaluated our model in terms of accuracy on a test set of 662."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Results\n",
    "\n",
    "Our neural network model yielded 0.989 testing accuracy, after going through 10 training epochs and having 1.000 training accuracy. Compared to a linear model we implemented with only a linear layer that scored 0.941 testing accuracy, our neural network model with a convolution layer and non-linear layer is much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Concluding Discussion\n",
    "\n",
    "Our project classified audio files as containing background noise or not with a highly accurate rate on unseen test data, yielding a successful neural network model. The data from Microsoft made it easy to integrate with python’s audio packages, and allowed us to customize the noisy files to our specifications. \n",
    "\n",
    "By converting 1-dimensional wav files into 2-dimensional Mel spectrograms, we were able to do image classification and use convolutional layers. This data is especially strong because it shows both amplitude and frequency over time, rather than just amplitude as a regular wav file does. The actual model pipeline was surprisingly simple, using only a 2d convolution layer, non-linear function, then flattening and a final linear layer to condense to the two possible outcomes.\n",
    "\n",
    "In the future, the changes we would like to see most are A) adding other languages to the dataset. By including other languages in the dataset, our model trains on more diverse data and then is able to recognize not just English, but any human-spoken language. This will ensure that in future applications that use this model, all languages will be treated equally. If the data fails to include more diversity in the languages and the model is applied to all languages, it could work against people and diminish the audio quality rather than improve it. Additionally, if we had more time we could B) remove the background noise, yielding clean speech files. This is the ultimate goal that this model could yield.\n",
    "\n",
    "The effectiveness of our model shows that denoising applications and cleaner digital audio are right around the corner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Group Contributions Statement\n",
    "\n",
    "<!-- When writing your group contributions statement, please keep in mind that everyone’s contributions are visible in the commit history of your GitHub repository. I do check these commit histories in case I suspect highly imbalanced divisions of labor.\n",
    "In your group contributions statement, please include a short paragraph for each group member describing how they contributed to the project:\n",
    "\n",
    "Who worked on which parts of the source code?\n",
    "Who performed or visualized which experiments?\n",
    "Who led the writing of which parts of the blog post?\n",
    "Etc. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Personal Reflection\n",
    "\n",
    "This is the only section that you are required to write individually and not with your project group.\n",
    "At the very end of your blog post, in a few paragraphs, respond to the following questions:\n",
    "\n",
    "What did you learn from the process of researching, implementing, and communicating about your project?\n",
    "How do you feel about what you achieved? Did meet your initial goals? Did you exceed them or fall short? In what ways?\n",
    "In what ways will you carry the experience of working on this project into your next courses, career stages, or personal life?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
